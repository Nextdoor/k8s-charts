{{ template "chart.header" . }}
{{ template "chart.description" . }}

{{ template "chart.versionBadge" .  }}{{ template "chart.typeBadge" .  }}{{ template "chart.appVersionBadge" .  }}

[deployments]: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/
[hpa]: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/

This chart provides a default deployment for a simple application that operates
in a [Deployment][deployments]. The chart automatically configures various
defaults for you like the Kubernetes [Horizontal Pod Autoscaler][hpa].

## Upgrade Notes

### 0.23.x -> 0.24.x

**BREAKING: Rolled back to Values.prometheusRules**

The use of nested charts within nested charts is problematic, and we have
rolled it back. Please use `Values.prometheusRules` to configure alarms. We
will deprecate the `prometheus-alerts` chart.

### 0.22.x -> 0.23.x

**BREAKING: The HorizontalPodAutoscaler has been upgraded to `v2beta2`**

The new `v2beta2` API has been used for the `HorizontalPodAutoscaler` - and a
custom set of `behaviors` have been implemented. See
`.Values.autoscaling.behavior for the details.

**NEW: PrometheusRules are enabled by default!!**

Going forward, the
[`prometheus-alerts](https://github.com/Nextdoor/k8s-charts/tree/main/charts/prometheus-alerts)
chart will be installed _by default_ for you and configured to monitor your
basic resources. If you want to disable it or reconfigure the alerts, the
configuration lives in the `.Values.alerts` key.

### 0.21.x -> 0.22.x

**BREAKING: If you do not set .Values.ports, then no VirtualService will be created**

In the past, the `.Values.virtualService.enabled` flag was the only control
used to determine whether or not to create the `VirtualService` resource. This
meant that you could accidentally create a `VirtualService` pointing to a
non-existent `Service` if your application exposes no ports (like a
"taskworker" type application).

Going forward, the chart will not create a `VirtualService` unless the
`Values.ports` array is populated as well. This links the logic for `Service`
and `VirtualService` creation together.

### 0.20.x -> 0.21.x

**BREAKING: Default behavior is to turn on the Istio Annotations/Labels**

We now default setting `.Values.istio.enabled=true` in the `values.yaml` file.
This was done because the vast majority of our applications operate within the
mesh, and this default behavior is simpler for most users. If your service is
_not_ running within the mesh, then you must set the value to `false`.


**BREAKING: ServiceMonitor has been replaced with PodMonitor**

We have replaced the behavior of creating a `ServiceMonitor` resource with a
`PodMonitor` resource. This is done because not all applications will use a
`Service` (in fact, the creation of the `Service` resource is optional), and
that can cause the monitoring to fail. `PodMonitor` resources will configure
Prometheus to monitor the pods regardless of whether or not they are part of a
Service.

**BREAKING: All .Values.serviceMonitor parameters moved to .Values.monitor**

We have condensed the Values a bit, so the entire `.Values.serviceMonitor` key
has been removed, and all of the parameters have been moved into
`.Values.monitor`. Make sure to update your values appropriately!

**BREAKING: Istio Injection is now explicitly controlled**

In previous versions of the chart, setting `.Values.istio.enabled=true/false`
only impacted whether or not certain lables and annotations were created... it
did not impact whether or not your pod actually got injected with the Istio
sidecar.

_As of this new release, setting `.Values.istio.enabled=true` will explicitly
add the `sidecar.istio.io/inject="true"` label to your pods, which will inject
them regardless of the namespace config. Alternatively, setting
`.Values.istio.enabled=false` will explicitly set
`sidecar.istio.io/inject="false"` which will prevent injection, regardless of
the namespace configuration!_

### 0.19.x -> 0.20.x

**Default Replica Count is now 2!**

In order to make sure that even our staging/development deployments have some
guarantees of uptime, the defaults for the chart have changed. We now set
`replicaCount: 2` and create a `podDisruptionBudget` by default. This ensures
that a developer needs to _intentionally_ disable these settings in order to
create a single-pod deployment.

**No longer setting `DD_ENV` by default**

The `DD_ENV` variable in a container will override the underlying host Datadog
Agent `env` tag. This should not be set by default, so we no longer do this. If
you explicitly set this, it will work ... but by default you should let the
underlying host define the environment in which your application is running.

### 0.18.x -> 0.19.x

**Automatic NodeSelectors**

By default the chart now sets the `kubernetes.io/os` and `kubernetes.io/arch`
values in the `nodeSelector` field for your pods! The default values are
targeted towards our most common deployment environments - `linux` on `amd64`
hosts. Pay close attention to the `targetOperatingSystem` and
`targetArchitecture` values to customize this behavior.

### 0.17.x -> 0.18.x

**New Feature: Secrets Management**

You can now manage `Secret` and `KMSSecret` Resources through `Values.secrets`.
See the [Secrets](#secrets) section below for details on how secrets work.

### 0.16.x -> 0.17.x

**New Feature: Customize User-Facing Ports**

You can now expose a custom port for your users (eg: `80`) while your service
continues to listen on a private containerPort (eg: `5000`). In the maps in
`.Values.ports` simply add a `port: <int>` key and the `Service` resource
will be reconfigured to route that port to the backend container port.

**Bug Fix: ServiceMonitor resources were broken**

Previously the `ServiceMonitor` resources were pointing to the `Service` but
the `Service` did not expose a `metrics` endpoint, which caused the resource to
be invalid. This has been fixed.

## Monitoring

This chart makes the assumption that you _do_ have a Prometheus-style
monitoring endpoint configured. See the `Values.monitor.portName`,
`Values.monitor.portNumber` and `Values.monitor.path` settings for informing
the chart of where your metrics are exposed.

If you are operating in an Istio Service Mesh, see the
[Istio](#istio-networking-support) section below for details on how monitoring
works. Otherwise, see the `Values.serviceMonitor` settings to configure a
Prometheus ServiceMonitor resource to monitor your application.

## Datadog Agent Support

This chart supports operating in environments where the Datadog Agent is
running. If you set the `Values.datadog.enabled` flag, then a series of
additional Pod Annotations, Labels and Environment Variables will be
automatically added in to your deployment. See the `Values.datadog` parameters
for further information.

## Istio Networking Support

### Monitoring through the Sidecar Proxy

[metrics_merging]: https://istio.io/latest/docs/ops/integrations/prometheus/#option-1-metrics-merging

When running your Pod within an Istio Mesh, access to the `metrics` endpoint
for your Pod can be obscured by the mesh itself which sits in front of the
metrics port and may require that all clients are coming in through the
mesh natively. The simplest way around this is to use [Istio Metrics
Merging][metrics_merging] - where the Sidecar container is responsible for
scraping your application's `metrics` port, merging the metrics with its own,
and then Prometheus is configured to pull all of the metrics from the Sidecar.

There are several advantages to this model.

* It's much simpler - developers do not need to create `ServiceMonitor` or
  `PodMonitor` resources because the Prometheus system is already configured to
  discover all `istio-proxy` sidecar containers and collect their metrics.

* Your application is not exposed outside of the service mesh to anybody - the
  `istio-proxy` sidecar handles that for you.

* There are fewer individual configurations for Prometheus, letting it's
  configuration be simpler and lighter weight. It runs fewer "scrape" jobs,
  improving its overall performance.

This feature is turned on by default if you set `Values.istio.enabled=true` and
`Values.monitor.enabled=true`.

## Secrets
A `Secret` or `KMSSecret` resource would be created and mounted into the container
based upon the `Values.secrets` and `Values.secretsEngine` being populated.
The `Secret` resource is generally used for local dev and/or CI test.
Secret` resources can be created by setting the following:
```
secrets:
  FOO_BAR: my plaintext secret
secretsEngine: plaintext
```
Alternatively, `KMSSecret` can be generated using the following example:
```
secrets:
  FOO_BAR: AQIA...
secretsEngine: kms
kmsSecretsRegion: us-west-2 (AWS region where the KMS key is located)
```

{{ template "chart.requirementsSection" . }}

{{ template "chart.valuesSection" . }}

{{ template "helm-docs.versionFooter" . }}
